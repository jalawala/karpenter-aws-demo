Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 5 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 2, 'nodesize=spot8vcpu32gb': 2}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 0
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Required no of pods i.e. 2 already running on Label: nodesize=spot4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 2 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 2 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 5
No of currently pending pods in namespace default for deployment nginx is 45
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 2 are already running. Scheduling remaining 22 pods
attempting to schedule 1/22 pod=nginx-675b694f5c-2gssj with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=2786.0 m and mem_free=13309864.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 1/22 pod=nginx-675b694f5c-2gssj on node=ip-192-168-62-139.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-62-139.ec2.internal cpu_free=2274.0 m mem_free=12261288.0 Ki
attempting to schedule 2/22 pod=nginx-675b694f5c-4czkt with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=2274.0 m and mem_free=12261288.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 2/22 pod=nginx-675b694f5c-4czkt on node=ip-192-168-62-139.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-62-139.ec2.internal cpu_free=1762.0 m mem_free=11212712.0 Ki
attempting to schedule 3/22 pod=nginx-675b694f5c-4wb6x with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=1762.0 m and mem_free=11212712.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 3/22 pod=nginx-675b694f5c-4wb6x on node=ip-192-168-62-139.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-62-139.ec2.internal cpu_free=1250.0 m mem_free=10164136.0 Ki
attempting to schedule 4/22 pod=nginx-675b694f5c-5zx9r with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=1250.0 m and mem_free=10164136.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 4/22 pod=nginx-675b694f5c-5zx9r on node=ip-192-168-62-139.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-62-139.ec2.internal cpu_free=738.0 m mem_free=9115560.0 Ki
attempting to schedule 5/22 pod=nginx-675b694f5c-6dqgc with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=738.0 m and mem_free=9115560.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 5/22 pod=nginx-675b694f5c-6dqgc on node=ip-192-168-62-139.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-62-139.ec2.internal cpu_free=226.0 m mem_free=8066984.0 Ki
attempting to schedule 6/22 pod=nginx-675b694f5c-8bgf9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 6/22 pod=nginx-675b694f5c-8bgf9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 2 are already running. Scheduling remaining 23 pods
attempting to schedule 1/23 pod=nginx-675b694f5c-8bgf9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=5776.0 m and mem_free=28776352.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 1/23 pod=nginx-675b694f5c-8bgf9 on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=5264.0 m mem_free=27727776.0 Ki
attempting to schedule 2/23 pod=nginx-675b694f5c-8frzq with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=5264.0 m and mem_free=27727776.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 2/23 pod=nginx-675b694f5c-8frzq on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=4752.0 m mem_free=26679200.0 Ki
attempting to schedule 3/23 pod=nginx-675b694f5c-8qfd4 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=4752.0 m and mem_free=26679200.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 3/23 pod=nginx-675b694f5c-8qfd4 on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=4240.0 m mem_free=25630624.0 Ki
attempting to schedule 4/23 pod=nginx-675b694f5c-8vmnw with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=4240.0 m and mem_free=25630624.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 4/23 pod=nginx-675b694f5c-8vmnw on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=3728.0 m mem_free=24582048.0 Ki
attempting to schedule 5/23 pod=nginx-675b694f5c-9jt4g with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=3728.0 m and mem_free=24582048.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 5/23 pod=nginx-675b694f5c-9jt4g on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=3216.0 m mem_free=23533472.0 Ki
attempting to schedule 6/23 pod=nginx-675b694f5c-b7xdk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=3216.0 m and mem_free=23533472.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 6/23 pod=nginx-675b694f5c-b7xdk on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=2704.0 m mem_free=22484896.0 Ki
attempting to schedule 7/23 pod=nginx-675b694f5c-bfn7x with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=2704.0 m and mem_free=22484896.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 7/23 pod=nginx-675b694f5c-bfn7x on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=2192.0 m mem_free=21436320.0 Ki
attempting to schedule 8/23 pod=nginx-675b694f5c-brp97 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=2192.0 m and mem_free=21436320.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 8/23 pod=nginx-675b694f5c-brp97 on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=1680.0 m mem_free=20387744.0 Ki
attempting to schedule 9/23 pod=nginx-675b694f5c-cm44h with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=1680.0 m and mem_free=20387744.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 9/23 pod=nginx-675b694f5c-cm44h on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=1168.0 m mem_free=19339168.0 Ki
attempting to schedule 10/23 pod=nginx-675b694f5c-cxhkp with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=1168.0 m and mem_free=19339168.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 10/23 pod=nginx-675b694f5c-cxhkp on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=656.0 m mem_free=18290592.0 Ki
attempting to schedule 11/23 pod=nginx-675b694f5c-d4qtd with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=656.0 m and mem_free=18290592.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 11/23 pod=nginx-675b694f5c-d4qtd on node=ip-192-168-51-161.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-51-161.ec2.internal cpu_free=144.0 m mem_free=17242016.0 Ki
attempting to schedule 12/23 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 12/23 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-51-161.ec2.internal with cpu_free=144.0 m and mem_free=17242016.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
failed scheduling 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=7800.0 m and mem_free=31447644.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 1/12 pod=nginx-675b694f5c-f2g4v on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=7288.0 m mem_free=30399068.0 Ki
attempting to schedule 2/12 pod=nginx-675b694f5c-ffv6j with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=7288.0 m and mem_free=30399068.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 2/12 pod=nginx-675b694f5c-ffv6j on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=6776.0 m mem_free=29350492.0 Ki
attempting to schedule 3/12 pod=nginx-675b694f5c-frdn9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=6776.0 m and mem_free=29350492.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 3/12 pod=nginx-675b694f5c-frdn9 on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=6264.0 m mem_free=28301916.0 Ki
attempting to schedule 4/12 pod=nginx-675b694f5c-fx9s8 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=6264.0 m and mem_free=28301916.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 4/12 pod=nginx-675b694f5c-fx9s8 on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=5752.0 m mem_free=27253340.0 Ki
attempting to schedule 5/12 pod=nginx-675b694f5c-fxfnf with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=5752.0 m and mem_free=27253340.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 5/12 pod=nginx-675b694f5c-fxfnf on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=5240.0 m mem_free=26204764.0 Ki
attempting to schedule 6/12 pod=nginx-675b694f5c-gzmkc with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=5240.0 m and mem_free=26204764.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 6/12 pod=nginx-675b694f5c-gzmkc on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=4728.0 m mem_free=25156188.0 Ki
attempting to schedule 7/12 pod=nginx-675b694f5c-htnqp with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=4728.0 m and mem_free=25156188.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 7/12 pod=nginx-675b694f5c-htnqp on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=4216.0 m mem_free=24107612.0 Ki
attempting to schedule 8/12 pod=nginx-675b694f5c-hzv9d with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=4216.0 m and mem_free=24107612.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 8/12 pod=nginx-675b694f5c-hzv9d on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=3704.0 m mem_free=23059036.0 Ki
attempting to schedule 9/12 pod=nginx-675b694f5c-jmthh with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=3704.0 m and mem_free=23059036.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 9/12 pod=nginx-675b694f5c-jmthh on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=3192.0 m mem_free=22010460.0 Ki
attempting to schedule 10/12 pod=nginx-675b694f5c-jxb8j with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=3192.0 m and mem_free=22010460.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 10/12 pod=nginx-675b694f5c-jxb8j on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=2680.0 m mem_free=20961884.0 Ki
attempting to schedule 11/12 pod=nginx-675b694f5c-kb87s with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=2680.0 m and mem_free=20961884.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 11/12 pod=nginx-675b694f5c-kb87s on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=2168.0 m mem_free=19913308.0 Ki
attempting to schedule 12/12 pod=nginx-675b694f5c-lbfn9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=2168.0 m and mem_free=19913308.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
Scheduled 12/12 pod=nginx-675b694f5c-lbfn9 on node=ip-192-168-20-102.ec2.internal with nodeLabel=nodesize=spot8vcpu32gb
node resources after scheduling pod: Label=nodesize=spot8vcpu32gb, node=ip-192-168-20-102.ec2.internal cpu_free=1656.0 m mem_free=18864732.0 Ki
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=1656.0 m and mem_free=18864732.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '30759bf8-08f9-4691-b798-55abcaaa16e0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:26:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-f2g4v\\": pod nginx-675b694f5c-f2g4v is already assigned to node \\"ip-192-168-20-102.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-f2g4v","kind":"pods/binding"},"code":409}\n'

Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 21
No of currently pending pods in namespace default for deployment nginx is 29
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=3810.0 m and mem_free=15407016.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '67f5cdc7-bca6-4d44-9103-549b7cff74e7', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:26:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-f2g4v\\": pod nginx-675b694f5c-f2g4v is already assigned to node \\"ip-192-168-20-102.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-f2g4v","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
Need 25 pods on Label: nodesize=spot8vcpu32gb and 13 are already running. Scheduling remaining 12 pods
attempting to schedule 1/12 pod=nginx-675b694f5c-f2g4v with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot8vcpu32gb
Checking free resources on node=ip-192-168-20-102.ec2.internal with cpu_free=1656.0 m and mem_free=18864732.0 Ki for nodeLabel=nodesize=spot8vcpu32gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3e14f730-90cf-43c9-aa91-3814a60cc004', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:26:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-f2g4v\\": pod nginx-675b694f5c-f2g4v is already assigned to node \\"ip-192-168-20-102.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-f2g4v","kind":"pods/binding"},"code":409}\n'

Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=3810.0 m and mem_free=15407016.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 1/17 pod=nginx-675b694f5c-mvdtk on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=3298.0 m mem_free=14358440.0 Ki
attempting to schedule 2/17 pod=nginx-675b694f5c-nwwmn with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=3298.0 m and mem_free=14358440.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 2/17 pod=nginx-675b694f5c-nwwmn on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=2786.0 m mem_free=13309864.0 Ki
attempting to schedule 3/17 pod=nginx-675b694f5c-q8lzn with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=2786.0 m and mem_free=13309864.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 3/17 pod=nginx-675b694f5c-q8lzn on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=2274.0 m mem_free=12261288.0 Ki
attempting to schedule 4/17 pod=nginx-675b694f5c-qsqcj with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=2274.0 m and mem_free=12261288.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 4/17 pod=nginx-675b694f5c-qsqcj on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=1762.0 m mem_free=11212712.0 Ki
attempting to schedule 5/17 pod=nginx-675b694f5c-stcgx with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=1762.0 m and mem_free=11212712.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 5/17 pod=nginx-675b694f5c-stcgx on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=1250.0 m mem_free=10164136.0 Ki
attempting to schedule 6/17 pod=nginx-675b694f5c-thrt9 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=1250.0 m and mem_free=10164136.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 6/17 pod=nginx-675b694f5c-thrt9 on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=738.0 m mem_free=9115560.0 Ki
attempting to schedule 7/17 pod=nginx-675b694f5c-tmmd4 with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=738.0 m and mem_free=9115560.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Scheduled 7/17 pod=nginx-675b694f5c-tmmd4 on node=ip-192-168-88-137.ec2.internal with nodeLabel=nodesize=spot4vcpu16gb
node resources after scheduling pod: Label=nodesize=spot4vcpu16gb, node=ip-192-168-88-137.ec2.internal cpu_free=226.0 m mem_free=8066984.0 Ki
attempting to schedule 8/17 pod=nginx-675b694f5c-ttftf with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 8/17 pod=nginx-675b694f5c-ttftf with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-62-139.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-88-137.ec2.internal with cpu_free=226.0 m and mem_free=8066984.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
failed scheduling 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd06aa2f1-10ea-4901-b40f-6d0c236f509e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:28:50 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3133163e-6788-4141-8394-83f889f7d557', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:01 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c805139d-6d43-4ac6-b2bd-b5325d4663f1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:13 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f4dc1173-78fd-4ed8-9006-b0098147629f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:24 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '37e3098c-d0ca-4561-8932-e226c851639f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:36 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6217560a-d514-46d0-848f-966522ee2710', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:47 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2752dca5-a137-4223-a306-c2808dc6bca0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:29:59 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '38efd15b-b9e5-40e7-9904-872d5167cf02', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:30:10 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5ba4d2c0-1031-4991-8bb4-90055f3ac4c4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:30:21 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e9262c66-1df3-4bae-a300-6801476424ac', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:30:33 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a4dbc468-afa8-4cbd-bb07-8477169ea11e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:30:44 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b28e1b07-102e-4636-aaf8-8da9b1c3ed59', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:30:56 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3228f275-dd3c-4429-a5e4-7a2d0e5026cf', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:31:07 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '930adcdc-c293-4b6b-ade9-6aa55289035f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:31:19 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4544b457-f1b3-40e4-bd60-4849458b67e7', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:31:31 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f050f0cd-b09c-4b57-a70f-55ce629d7551', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:31:42 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b7bb8b92-a3a1-4716-9cbd-1662bab84168', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:31:53 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d65c6c1-4d29-4d21-86d6-49e0433edc73', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:32:05 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '600afbd8-c851-4f30-abb5-9991d56bf527', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:32:16 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '986d5ba6-3001-4556-a810-51ba50f4d481', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:32:28 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a0da04e1-5795-496d-a485-d9cc3e800c95', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:32:39 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'baa7156b-454c-4f7d-805a-bd3867dcbe0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:32:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7bd10343-ac3f-4c64-ac2a-495edc118be1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:33:02 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1438ec47-2065-4109-823c-2d2dd57998b0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:33:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1301cb23-551a-41cc-b229-1845a87fd32d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:33:25 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7f22d450-59c8-4a83-a440-7100b39d16c8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:33:37 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bcf049d5-b364-4c32-87f6-293bb21e87b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:33:48 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9ff995c9-2a26-4975-b6f8-40d431c6c9c9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:00 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3b46fcda-2bc3-4319-95f3-e8910179b0f3', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:11 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '98f5db84-b640-4452-9377-3f7cda9acb79', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5c0faeb9-23b9-4a79-acfb-ebe9b040d67b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '168f6645-6d8c-464f-b537-13debe807b00', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '98969adc-0795-454e-9c48-d82a09fe334e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:34:57 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '08a8fe55-d053-4508-ad1d-8fecefefeaf8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:35:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7984b2fd-a9c2-4a82-8e83-1381432592d9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:35:20 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7e6b15a3-a73a-4acf-9f5f-c6e7941ab34e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:35:32 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd994fddf-5593-4bf7-afa3-beca5f51551c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:35:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3843b3db-e5b9-4bdc-ae5e-1e3ccb215d8c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:35:55 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e4c1f194-fafb-441c-aaf9-8723fab58461', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:36:06 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'efa4b9ed-0978-4c5f-ac4e-e20be24cce6a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:36:18 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6edb9137-5988-44cd-80b7-11561188897c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:36:29 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '05d2bae5-6b87-4bf5-b2f5-d2e79252fbf8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:36:41 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a834f9ef-13b0-497e-9752-61f83dc43934', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:36:52 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bfc4b147-cc64-4a00-990e-bba405892be0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:37:04 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ccbd8179-5678-4208-8ba8-2931d9898fc6', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:37:15 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1877edc0-13b4-44c8-8a66-2c08d8c70bfd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:37:27 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3cbc0752-c2f7-4db1-a273-0cb1127695a9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:37:38 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '70ffba00-0355-4e10-ab1f-1617941e619d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:37:50 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '697f1fc4-78d8-4e4e-a50a-befb3d6b6e0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:01 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '06856fea-f308-4240-b39b-192ce509cd18', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:13 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7a737c03-472e-4803-b951-b629ab5f22d0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:24 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b6f9699a-0fb0-4809-9764-98455f5e4cbf', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:36 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b3bee066-7047-484a-ad1e-e498fb5399e1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:47 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '460fbc31-8ee5-4766-8af0-9b0f82123c7b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:38:59 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '36d112de-942b-454b-a4e0-5e6a671fcaac', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:39:10 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cdf95a71-e886-417f-b4b6-92f253741aed', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:39:22 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f6e1c43d-e6b8-45e9-9da5-8dabffe2389c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:39:33 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '093ebc88-1dd5-4eb8-a97f-5befccd26054', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:39:45 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '25e16983-a3c4-458a-846d-d90fe1b2f4a4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:39:56 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9c4cb080-2d70-4b70-ac4b-32cdea8908f3', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:40:08 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '70b71761-4bc8-4a4c-abc3-d6a2d585485e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:40:20 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'aee1f1c0-4307-4ce8-a942-9c7c793fc052', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:40:31 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'fee84aed-868a-4ddd-b48b-5d7a75e0466d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:40:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f94aa2c6-2626-4d0d-8188-4347363adf88', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:40:54 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c32ee57a-be6a-424c-b673-c578d22864b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:41:05 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a5a6f95f-9062-4000-ba81-d77d67ddbd7f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:41:17 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0d332811-3ab4-42e1-8b8a-368c374e0a4a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:41:28 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '50556e9c-79a5-460e-b3ee-652a7b87c1ca', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:41:40 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '46bf2482-bfc8-4118-9fa4-bf57f7a10158', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:41:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bee0fc94-3021-498b-af42-f0da030e143a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:42:03 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8388f322-7144-4e96-abc2-5adf1c4b2e50', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:42:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7f767099-5802-4b1f-9d2c-25722af8b4b9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:42:26 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1ff6bc9f-7716-4190-b5dd-5339798d4670', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:42:37 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a809f268-ef16-44f5-9462-ed1c34168c2a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:42:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4e4671b7-153a-40ec-a0ef-f703f4178348', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:00 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '61619d87-52dd-4c50-8638-ee463da63272', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:12 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c48cbf0b-dbef-47c5-a6c1-4b6d1059e20c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e23cb876-2aa9-4985-96c5-1d044801e9ca', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:35 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '31692074-d544-46f8-9019-e037794863a1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4ba50241-f957-4d9a-83bc-e82330e65e9b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:43:58 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ecb3a904-bcdf-4c9a-87de-387d0fce3348', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:44:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '83d17aae-7a00-4331-97d5-89a50136a8d8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:44:21 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1301dce3-f92b-49b4-886c-4f189564d772', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:44:32 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd6417dd3-c145-4397-b897-1a437467f11b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:44:44 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8b247cb2-7ff1-4496-bb4f-4d01ac8a02fc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:44:55 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '915ad6fe-19df-4b70-9c47-15ee212b816c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:45:07 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'eee51e73-cee3-40aa-9519-5d927422a232', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:45:18 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8a159ff2-a8bb-47e1-885d-cd3ec34e260a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:45:30 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6348772f-ce24-4dbf-bc7c-ed31739e4650', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:45:41 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e4081fc8-fc51-4fdf-8955-1b6fcf239885', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:45:53 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '579f82eb-298c-44a0-8712-f7cea8a85bc2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:46:04 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9cd07cdb-7076-4386-b6ba-0dbaee8af9fd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:46:16 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '69246d2e-665b-4cf7-8cfe-5a5d799ffd12', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:46:27 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9484b486-7afd-4f96-8409-f63c40738386', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:46:39 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '7f243da1-927e-439e-9b8e-eab2fcde325d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:46:50 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd8ddaf98-7105-438f-b1c3-47c6a960c8fd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:02 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '780b124f-4abc-4e6c-b132-615c7eb95434', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:13 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9bc353d3-8a19-4b23-a471-c4c1c17fd8f1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:25 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5d1fb376-3572-480e-aa09-2059be06b63a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:36 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4c163f2f-b282-4d1a-ad3d-d68bc512b2c7', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:48 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '23d3dc4d-6802-4688-a1e7-5fc9c700e668', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:47:59 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cae86c79-3f58-4668-a9db-1e6a3654f110', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:48:11 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b0ce3086-b38b-4049-afaf-382fa04acbdb', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:48:22 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8ffd6772-d01b-49f8-b309-2118e36b2aa1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:48:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '01f4eaec-55f5-4378-bdc4-f44b14096510', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:48:45 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8629686-af37-49e3-9c18-d9d9a62887ca', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:48:57 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '155da4a9-7792-48bb-a55f-fc374411efae', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:49:08 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'acb47235-6f59-45a9-9394-8d9f32f7638c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:49:19 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f7be7ee5-fdeb-434e-b6ad-fc7766204948', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:49:31 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4f845383-73a8-498d-a52d-18e8ad524ba3', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:49:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6807fa42-3646-4091-829d-57ba6bf2e387', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:49:54 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '567711d5-01dc-413d-add2-5bc63e622728', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:50:05 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b0a3c540-4722-44c5-97bf-3ead77116fd8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:50:17 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '06ff1060-da8c-40f6-a160-d71485f8162b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:50:28 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b7e2e3af-b3d7-467a-b34e-6b3055c92cda', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:50:40 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1ef879e7-8f73-4996-933c-fc2f44e51837', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:50:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '420fdca8-1966-4540-a2f5-ab2614554284', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:51:03 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '43257222-9f15-436f-b8ce-70f0e588bc80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:51:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '66e324ea-dd7a-4e1b-b7b2-f6e4bf9af470', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:51:26 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '99dc9b27-f69f-4856-89e5-ba65148b8125', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:51:37 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '020362dd-c775-496a-9171-a6bf5801de9c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:51:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0bb71157-6794-47d1-8c39-c12b5c1cfa0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:00 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c525e672-62e6-4a8f-9ac6-c9cb0d0a9850', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:12 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '62a5c662-9178-4d34-9fcb-574eb172b230', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'eaeebf7c-ac78-4ea2-b333-e4df153d75ff', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:35 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '51a994e8-0880-4c77-a807-f40d3c7d9b23', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b976d50a-ed9d-49b8-9085-d7e27e844673', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:52:57 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '27441d25-4cac-4f53-96ee-42c864e00266', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:53:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8c2a251c-f345-4dc9-b2fb-33e5d18d7547', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:53:20 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b77f6b06-66c6-41ca-937c-b1ce585204f5', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:53:31 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9d855438-e2f4-4693-be70-2d56d11dc68e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:53:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f15442c1-4f5c-408e-92ff-68b3d0d30b40', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:53:54 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3577b799-89c9-4f26-8f59-1490680513ce', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:54:06 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '72023f34-ca3f-486f-950c-733a125e701b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:54:17 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2ae7229f-f4ea-4fb6-b365-58d2c33d49ca', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:54:29 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'eec68d52-8342-446e-bd47-bed523b5d656', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:54:40 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0cc08b4d-3277-4312-be52-b05a9f1d1309', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:54:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5642f284-644c-42f3-aa57-f5dcb1248fff', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:55:03 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '588e9221-5f9b-49a4-8232-dc368788d115', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:55:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '842016a4-8650-4f01-9cfa-02ea02a0e636', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:55:26 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd3544326-ac98-4d52-b6ac-48e1a7867c2c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:55:38 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e7a9c42e-9c45-40fc-aa45-8964a54eef12', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:55:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0ca2b604-9cf7-4e41-8aa1-17659885839d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:01 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '994c5ffd-dc5e-4b56-ad86-6096b8a6b823', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:12 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cc82af83-eed6-41b7-b2ab-d123c47275c3', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '38a01867-e0ee-4995-8d0d-861abacbb832', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:35 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4c01d0fd-1467-4538-9c81-41b5b5e67818', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '36c16749-b27e-4700-9687-56288a3bcf54', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:56:58 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1569b167-c123-47a9-9965-8de4d631f723', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:57:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c2d04236-4b91-4a4b-8aec-3cd945adec19', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:57:21 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '835db8c3-e1c3-41f4-bcaa-e8e7275d4ba8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:57:32 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ddc5d646-c5c5-4380-a18f-c2c48ff542a3', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:57:44 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bec00528-02a1-4937-bc63-3a7450f35797', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:57:55 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e6ff49f-6a1b-4d57-a3e8-78b6c5e628ef', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:58:07 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f677a4f8-031c-44a1-83cc-bb5a09ffb5bb', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:58:18 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3e28e5bd-25d2-48aa-b54e-8362a8f3c251', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:58:30 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c4abea2d-6acd-4765-91ce-319df08f8962', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:58:41 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0ab7e5a7-f087-4bea-bae9-9950d777c681', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:58:52 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'da86ce86-0970-40c6-9132-24cf6a424e55', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:59:04 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '67b38255-11dc-4b36-9611-301bbfe1c572', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:59:15 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5c99bdb9-30a3-417e-b66a-e8ea0d5580e4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:59:27 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5b165aec-5f2c-4e86-a1a3-4e031e2fa933', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:59:39 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ec251a19-b10e-436e-a57e-84f8fce59f28', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 02:59:50 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '145608e8-d0b5-45c0-a768-544a150aec27', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:02 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '882100a4-e501-4454-b477-e651ba3dda65', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:13 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '77f98fd7-e081-4ffc-951c-b5e81322a968', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:25 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '181e101e-37da-4134-a091-2a24ee2add10', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:36 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '92e38ef6-5b9d-455a-8434-b2bd563dffab', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:48 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '859ba481-8aba-4adf-8d88-5911cb44c5df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:00:59 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bb45ea81-78fb-4c70-9802-ac065a77d025', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:01:11 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a946d213-67b9-47e0-b95a-fefc8d67e86f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:01:22 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'facd51e2-6e59-4bfe-8866-c9a31b47d6da', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:01:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b9f6434d-06e8-4fbb-a182-43e9ab8addd6', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:01:45 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '87f49db3-92e5-4cbe-9f8b-70b13abe5fb4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:01:56 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '650f8089-2bda-4c68-a626-42661f4668ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:02:08 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '43ec3659-f578-4000-a3a6-4024e216c77d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:02:19 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '482f5c99-9883-42d3-a0c4-6dba564c1236', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:02:31 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '46eabe8f-0d57-4bbb-88e8-60f26ac57ac9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:02:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e7ba9f91-2044-420a-9136-968253b0b4af', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:02:54 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ae43b35c-ea95-4c19-84b2-6ca5d91c9f9a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:03:05 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4779c8ae-f23b-4d92-a1de-acc2198a59b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:03:17 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd388fde4-7d66-4dcb-8428-91cd7d2235bd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:03:28 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '265aa2f3-12b1-4abe-b70e-aab2eefd8ec8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:03:40 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '89cd063d-26f7-4e38-808d-5dd48731e934', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:03:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '05d06616-cbe3-4f83-8055-e432c95fb683', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:04:03 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b91b0318-8491-47b3-8378-f6cb9e8529a8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:04:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0487ac20-f5b0-4f16-80ab-e4c7eed6fbb4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:04:26 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0f817963-a8fa-401b-8870-df24bd8356b5', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:04:37 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8235c0a-cba2-4891-bce2-f7f4ced2a615', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:04:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a728737f-a52c-4041-aca6-60202723b5a5', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:00 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8201afc3-9a83-4251-9696-d3e433c25752', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:11 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e3a04b75-9913-4827-a86f-a01d39c54f4d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ba6a9828-e34a-4971-9096-f409e396563c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '077f566d-3eb8-484c-9118-90ed247a4380', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2743883c-a08f-476d-b5e9-3e641d2465db', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:05:57 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1183c1ef-0af2-49cc-9cd7-db793d318a63', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:06:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '0df1af22-0d1e-482e-82a0-b04934689058', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:06:20 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd04139dd-15b0-4880-9f35-db310f3bf143', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:06:32 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'a24ab885-399f-435d-b8c8-e5ada7983491', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:06:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1838e772-7a89-4698-9188-a204a98dde13', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:06:55 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '58916c9c-e843-4155-a4ec-2f4c4b7041d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:07:06 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '27aa5c4b-f8dc-4a5a-91f4-c5767cee66e0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:07:18 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '779999a9-2168-45fa-8721-9144da87457f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:07:29 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '05093827-5321-4f1e-b2be-d6676ab13d32', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:07:41 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'df5cb2a8-ff4d-4200-a78d-aa24e0acdcaa', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:07:52 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c1fac421-e412-4e6e-82a0-5dca06cf9231', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:08:04 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e9b6c8bb-6f86-4513-b56b-f9a890a4409f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:08:15 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '320a686c-354b-4fa2-87a7-27ee9cb659da', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:08:27 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8c56fba7-0f25-4a3e-be0f-8ac664e0648e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:08:38 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6aba9271-0e37-49e3-a7b5-0a19e56c3a09', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:08:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '72be9285-6f63-4fe4-9655-4cdb4d31a822', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:01 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f5816095-1b90-45d2-ba91-6fbbd3c989b6', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:13 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '22be4afc-7f00-45c2-838d-dafeea4d76ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:24 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5f529e42-b8cf-430d-a723-d8bee3e95e22', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:36 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ba55ceed-94e5-437b-80e1-75fb7e42b546', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:47 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6fbecf2f-3b0f-4f9d-a38d-5b6d2e829dcb', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:09:59 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '97f1e7bb-9783-4c70-82b6-7585f2b22371', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:10:10 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '8650aa8a-6a55-4c49-ab76-8d31d261598c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:10:21 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '128b3ab3-b2fb-4259-ab62-f3dfe6be9e3d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:10:33 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd9e74fdd-b071-42e7-99fd-226f14d47012', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:10:44 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6b4e2397-1d57-4000-91be-72033bed6a4c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:10:56 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bb15013b-4f7c-40fd-bd7a-71184f464dbd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:11:07 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cca9a819-7fe4-40f0-adf9-083ed3a3671b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:11:19 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '35aaa8b6-67a1-4534-be1c-968a26b51f90', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:11:30 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b49c9564-24fc-4b18-bf4c-691acf1b5e3f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:11:42 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f3e5d0ea-289f-46cf-9d81-60b38e1c546c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:11:53 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6097b73c-d538-4c19-bc56-eb6e29f55b72', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:12:05 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3662160d-906c-435c-aa9b-b32c7e25d514', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:12:16 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '21ed7041-9911-4a50-9143-891259490b56', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:12:28 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f1b51764-e74b-4170-b011-5861f4389392', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:12:39 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '18a6f986-ee15-41d0-b1f0-659252e8c5f9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:12:51 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '26e7307e-bcf7-429a-a020-943c18d7052f', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:13:02 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1855ac1c-b561-422a-b702-ea760c583f7c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:13:14 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '3ea4f536-2ba6-4bdf-a5e2-d61037a47066', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:13:25 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '46fe3597-872f-4a88-8d3b-4e2a66edcf05', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:13:37 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4ed4218d-93c3-4aba-b37b-a8825d110ade', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:13:48 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd7fe2205-9d27-4ba1-959c-5e4bde8f92da', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:00 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '76fd28b4-a9e7-415a-9464-12e8d6e28e15', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:11 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'f924241f-a8e2-4e48-a5db-1b144455dff9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:23 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2a8db4f4-243e-4172-a311-f7ae6007a712', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:34 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '39be438c-b9f1-4dbb-9b56-81db142ac9be', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd4f8c6e9-b234-406a-aeaf-292de61d80b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:14:57 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '71061c98-d302-4205-bc59-6edcbe811359', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:15:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e8865cbb-2ae4-411d-933b-83d5845070f0', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:15:20 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9733e05e-3ad0-4af9-a16a-363f227b7e56', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:15:32 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'db843507-91a8-4c65-ac6a-598dc9573a44', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:15:43 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9edc319e-406b-4bb2-ac86-e82d1a68282c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:15:55 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '4f5610be-6439-4c60-bfa3-71deeaeed824', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:16:06 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '417e12d6-7d7b-4627-b36e-e8bfc5dec95a', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:16:18 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '838d0190-7e8d-42ea-99ef-483beecd3fcb', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:16:29 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'dc66984c-b372-4334-be67-fffbe951867b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:16:40 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5267c1c4-00f3-4742-9fe5-8c2711745c84', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:16:52 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'be6a6692-28fe-41f9-a87f-3693099ea802', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:17:04 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b3d9bc34-f310-4b36-b572-2e59cde2701b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:17:15 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bfd9acf7-4aa3-4fa9-a5e9-5f7568a6de82', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:17:26 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '41f74cdc-f3d0-45d9-9309-1165ab813911', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:17:38 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '58234fb3-009f-4118-871d-dfc04f443f62', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:17:49 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e46230fd-d853-4ba3-8690-383005907641', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:01 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '36d4b926-79f1-4b41-ab6b-f47187c1bbc2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:12 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '80709c89-fc74-4cc1-bf0c-964f12f5e11e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:24 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b027f8c4-eef0-4be3-899a-a20d92ba86a9', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:35 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'acf75d75-6090-49ae-a1ce-8ce0e044da02', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:46 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'fd5c114c-6039-4035-b7a4-ddc90891154c', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:18:58 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
No of currently running pods in namespace default for deployment nginx is 33
No of currently pending pods in namespace default for deployment nginx is 17
No of currently failed pods in namespace default for deployment nginx is 0
Available node with Label: nodesize=od4vcpu16gb i=1 node=ip-192-168-73-104.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=1 node=ip-192-168-2-121.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=2 node=ip-192-168-26-176.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=3 node=ip-192-168-62-139.ec2.internal
Available node with Label: nodesize=spot4vcpu16gb i=4 node=ip-192-168-88-137.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=1 node=ip-192-168-20-102.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=2 node=ip-192-168-51-161.ec2.internal
Available node with Label: nodesize=spot8vcpu32gb i=3 node=ip-192-168-80-91.ec2.internal
CustomScheduleStrategy needs 1 pods running on Label: nodesize=od4vcpu16gb
i=1 pod=nginx-675b694f5c-tckps already runs on node=ip-192-168-73-104.ec2.internal Label: nodesize=od4vcpu16gb
Required no of pods i.e. 1 already running on Label: nodesize=od4vcpu16gb. So no need to Schedule !!
CustomScheduleStrategy needs 24 pods running on Label: nodesize=spot4vcpu16gb
i=1 pod=nginx-675b694f5c-2gssj already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=2 pod=nginx-675b694f5c-4czkt already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=3 pod=nginx-675b694f5c-4wb6x already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=4 pod=nginx-675b694f5c-5zx9r already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=5 pod=nginx-675b694f5c-6dqgc already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=6 pod=nginx-675b694f5c-c9vlx already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
i=7 pod=nginx-675b694f5c-qnx4t already runs on node=ip-192-168-62-139.ec2.internal Label: nodesize=spot4vcpu16gb
Need 24 pods on Label: nodesize=spot4vcpu16gb and 7 are already running. Scheduling remaining 17 pods
attempting to schedule 1/17 pod=nginx-675b694f5c-mvdtk with cpu_req=512 m mem_req=1 Gi for nodeLabel=nodesize=spot4vcpu16gb
Checking free resources on node=ip-192-168-2-121.ec2.internal with cpu_free=3810.0 m and mem_free=15105320.0 Ki for nodeLabel=nodesize=spot4vcpu16gb
(409)
Reason: Conflict
HTTP response headers: HTTPHeaderDict({'Audit-Id': '601f659b-8d9b-4729-87da-5d9e3dcfc41d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Wed, 03 Feb 2021 03:19:09 GMT', 'Content-Length': '342'})
HTTP response body: b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Operation cannot be fulfilled on pods/binding \\"nginx-675b694f5c-mvdtk\\": pod nginx-675b694f5c-mvdtk is already assigned to node \\"ip-192-168-88-137.ec2.internal\\"","reason":"Conflict","details":{"name":"nginx-675b694f5c-mvdtk","kind":"pods/binding"},"code":409}\n'

CustomScheduleStrategy needs 25 pods running on Label: nodesize=spot8vcpu32gb
i=1 pod=nginx-675b694f5c-8bgf9 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=2 pod=nginx-675b694f5c-8frzq already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=3 pod=nginx-675b694f5c-8qfd4 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=4 pod=nginx-675b694f5c-8vmnw already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=5 pod=nginx-675b694f5c-9jt4g already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=6 pod=nginx-675b694f5c-b7xdk already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=7 pod=nginx-675b694f5c-bfn7x already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=8 pod=nginx-675b694f5c-brp97 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=9 pod=nginx-675b694f5c-c4xs8 already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=10 pod=nginx-675b694f5c-cm44h already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=11 pod=nginx-675b694f5c-cxhkp already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=12 pod=nginx-675b694f5c-d4qtd already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=13 pod=nginx-675b694f5c-f2g4v already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=14 pod=nginx-675b694f5c-ffv6j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=15 pod=nginx-675b694f5c-frdn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=16 pod=nginx-675b694f5c-fx9s8 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=17 pod=nginx-675b694f5c-fxfnf already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=18 pod=nginx-675b694f5c-gzmkc already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=19 pod=nginx-675b694f5c-htnqp already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=20 pod=nginx-675b694f5c-hzv9d already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=21 pod=nginx-675b694f5c-jkkcl already runs on node=ip-192-168-51-161.ec2.internal Label: nodesize=spot8vcpu32gb
i=22 pod=nginx-675b694f5c-jmthh already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=23 pod=nginx-675b694f5c-jxb8j already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=24 pod=nginx-675b694f5c-kb87s already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
i=25 pod=nginx-675b694f5c-lbfn9 already runs on node=ip-192-168-20-102.ec2.internal Label: nodesize=spot8vcpu32gb
Required no of pods i.e. 25 already running on Label: nodesize=spot8vcpu32gb. So no need to Schedule !!
Running RunCustomKubeScheduler loop !!!
Found CustomPodScheduleStrategy : nodesize=od4vcpu16gb,base=1,weight=0:nodesize=spot4vcpu16gb,weight=1:nodesize=spot8vcpu32gb,weight=1 for deployment nginx with numOfReplicas 50 in namespace default
namespace=default deploymentName=nginx CustomSchedulingData={'nodesize=od4vcpu16gb': 1, 'nodesize=spot4vcpu16gb': 24, 'nodesize=spot8vcpu32gb': 25}
